{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用以定義dictionary的資料結構\n",
    "from collections import defaultdict \n",
    "\n",
    "#同作業一，斷出term的\n",
    "import nltk\n",
    "import string\n",
    "# from collections import Counter\n",
    "from nltk.stem.porter import PorterStemmer #import porter algorithm的套件\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#打開文檔並讀取\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import operator\n",
    "import sys\n",
    "\n",
    "#random select\n",
    "import random\n",
    "\n",
    "#計算用的sqrt（） log（）\n",
    "import math\n",
    "\n",
    "#csv寫入\n",
    "import csv\n",
    "\n",
    "#矩陣用\n",
    "import numpy as np\n",
    "\n",
    "#計算程式運行時間\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF(string):\n",
    "    tf = defaultdict(int) #建立Dictionary的資料結構，以term作爲key，頻率做value，e.g. 'word' : 3\n",
    "    #hw1的方式產出term\n",
    "    res = nltk.word_tokenize(string)\n",
    "    porter = PorterStemmer()  \n",
    "    stemmer = [ porter.stem(element) for element in res]  #stemming\n",
    "    stop = set(stopwords.words('english'))\n",
    "    final = []\n",
    "    for s in stemmer:\n",
    "        if s not in stop and len(s) > 1:\n",
    "            if s.isalpha():       #判斷是否為英文字母\n",
    "                final.append(s)\n",
    "    for t in final:              #將斷出來的字統計為term的次數\n",
    "        tf[t] += 1\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term(word):\n",
    "    res = nltk.word_tokenize(word)\n",
    "    porter = PorterStemmer()  #定義方法\n",
    "    stemmer = [ porter.stem(element) for element in res]  #stemming\n",
    "    stop = set(stopwords.words('english'))\n",
    "    final = []\n",
    "    for s in stemmer:\n",
    "        if s not in stop and len(s) > 1:\n",
    "            if s not in final:  #避免出現重複的詞，防止一個term在同一篇文章出現2次以上而使 DF 算 2次\n",
    "                final.append(s)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "def sortdict(x):\n",
    "    new = {}\n",
    "    for word in x:\n",
    "        new[word] = index[word]\n",
    "    sort = sorted(new.items(), key=operator.itemgetter(1))  #根據dictionary的value來排序\n",
    "    sort = dict(sort)\n",
    "    return sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(d1, d2):  #傳入數值，為document id，這次作業以 1，2為計算對象\n",
    "    path = 'tfidf'  #讀取 d1,d2 兩份文件的位置\n",
    "    #將document id 轉爲對應的檔名\n",
    "    xfile = str(d1) + '.txt'\n",
    "    yfile = str(d2) + '.txt'\n",
    "    \n",
    "    #定義存取兩個文件的 unit vector\n",
    "    x = {}\n",
    "    y = {}\n",
    "    \n",
    "    c = 1\n",
    "    #打開第一份文件讀取\n",
    "    fix = os.path.join(path, xfile)\n",
    "    with open(fix, 'r') as fx:\n",
    "        for line in fx:    #由於在儲存時，將 first line作爲該column的title，因此需從 second line讀\n",
    "            if c <= 2:\n",
    "                c +=1\n",
    "                continue\n",
    "            (key, val) = line.split()  #讀取 term index 和 normalize過後的 tfidf\n",
    "            x[key] = val\n",
    "    \n",
    "    #第二份文件的處理，同第一份文件\n",
    "    cou = 1\n",
    "    fiy = os.path.join(path, yfile)\n",
    "    with open(fiy, 'r') as fy:\n",
    "        for line in fy:\n",
    "            if cou <= 2:\n",
    "                cou +=1\n",
    "                continue\n",
    "            (key, val) = line.split()\n",
    "            y[key] = val\n",
    "    \n",
    "    summ = 0.0   #用以累加個内積的值\n",
    "    #以第一份文件找第二份文件有無對應到的term\n",
    "\n",
    "    for s in x:\n",
    "        if s not in y:   #若 x存在一 term是 y沒有的，則將這個 term設給 y，值為 0，方便之後做内積\n",
    "            y[s] = 0\n",
    "        summ = summ + float(x[s])*float(y[s])  #unit vector内積，極爲 2 documents的相似度\n",
    "\n",
    "    return summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[      -inf 0.20113796 0.30104544 ... 0.03777052 0.02942304 0.0497299 ]\n",
      " [0.20113796       -inf 0.20126398 ... 0.02986856 0.01167086 0.02317333]\n",
      " [0.30104544 0.20126398       -inf ... 0.04507046 0.02447444 0.04011235]\n",
      " ...\n",
      " [0.03777052 0.02986856 0.04507046 ...       -inf 0.13256605 0.02298185]\n",
      " [0.02942304 0.01167086 0.02447444 ... 0.13256605       -inf 0.01967375]\n",
      " [0.0497299  0.02317333 0.04011235 ... 0.02298185 0.01967375       -inf]]\n",
      "--- 1593.7882721424103 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "matrix = np.zeros((1095, 1095))\n",
    "I = []\n",
    "#建立矩陣\n",
    "for n in range(0, 1095):   \n",
    "    for i in range(0, 1095):\n",
    "        if(n == i):          # n 跟 i 相等，也就是自己與自己的相似度一定會很大，因此設成， 日後不會被挑到\n",
    "            matrix[n][i] = float('-inf')\n",
    "        else:\n",
    "            x = n + 1\n",
    "            y = i + 1\n",
    "            matrix[n][i] = cosine(x, y) #index從0開始，要記得加一\n",
    "    I.append(1)  #存有哪些\n",
    "print(matrix)\n",
    "\n",
    "print(\"time of building matrix: \")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.dump(\"matrix.dat\")  #存入本地端"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#取最大值\n",
    "def arg(mtx, I):\n",
    "    maxima = float('-inf')\n",
    "\n",
    "    for x in range(0, 1095):\n",
    "        for y in range(0, 1095):\n",
    "            if (I[x] + I[y]) == 2 and x != y and mtx[x][y] > maxima:\n",
    "                maxima = mtx[x][y]\n",
    "                re = [x, y]\n",
    "\n",
    "    return re[0], re[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def HAC_CompleteLink(k):\n",
    "    I = [1] * 1095\n",
    "    A = []  #結果 list\n",
    "    K = 1095 - k\n",
    "    \n",
    "    #加載建立好的 matrix\n",
    "    matrix = np.load(\"matrix.dat\")\n",
    "    \n",
    "    #clustering\n",
    "    for k in range(0, K):\n",
    "        \n",
    "        #取最大值的 2個 cluster\n",
    "        x, y = arg(matrix, I)\n",
    "        sets = set([x, y])  #存成 set\n",
    "\n",
    "        flag = True    #看 結果list 有沒有可以合并的，合并成功改成 false\n",
    "\n",
    "        concat = []   # 合并成功的結果\n",
    "        delete = []   # 原本參與合并的要刪掉\n",
    "        for item in A:\n",
    "            if len(item.intersection(sets)) > 0:   #有交集的item記錄下來\n",
    "                temp = item.union(sets)\n",
    "                concat.append(temp)\n",
    "                delete.append(item)\n",
    "                flag = False\n",
    "\n",
    "\n",
    "        if flag:     #沒有合并成功，加入新的 pair\n",
    "            A.append(sets)\n",
    "        else:        #合并成功就加入合并結果，并把原本參與合并的item刪除\n",
    "            for dlt in delete:\n",
    "                A.remove(dlt)\n",
    "            add = set()\n",
    "            for con in concat:\n",
    "                add = add.union(con)\n",
    "            A.append(add)\n",
    "            \n",
    "        #更新cluster之間的距離\n",
    "        for j in range(0, 1095):   \n",
    "            matrix[x][j] = min(matrix[x][j], matrix[y][j])\n",
    "            matrix[j][x] = min(matrix[j][x], matrix[j][y])\n",
    "            \n",
    "            \n",
    "        #標記為已被合并\n",
    "        I[y] = 0    \n",
    "        \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分群結果存入 file\n",
    "def save(clusters):\n",
    "    filename = str(len(clusters)) + '.txt'\n",
    "    file = open(filename, \"wt\")\n",
    "    for c in clusters:\n",
    "        for doc in sorted(c):\n",
    "            file.write(str(doc + 1) + '\\n')\n",
    "        file.write('\\n')\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster8 = HAC_CompleteLink(8)\n",
    "save(cluster8)\n",
    "\n",
    "cluster13 = HAC_CompleteLink(13)\n",
    "save(cluster13)\n",
    "\n",
    "cluster20 = HAC_CompleteLink(20)\n",
    "save(cluster20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
